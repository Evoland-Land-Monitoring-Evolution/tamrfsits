optimization_parameters:
  _target_: tamrfsits.tasks.base.OptimizationParameters
  learning_rate : 0.0001
  minimum_learning_rate: 0.00002
  t_0 : 40360
  t_mult : 2
  weight_decay: 0.
  nb_warmup_steps: 2018 # 1 epoch of linear warmup
  loss :
    _target_: torch.nn.SmoothL1Loss
    beta : 0.1

standardization_parameters:
  _target_: tamrfsits.tasks.base.StandardizationParameters
  hr_mean :   ${datamodule.hr_mean}
  lr_mean : ${datamodule.lr_mean}
  hr_std  : ${datamodule.hr_std}
  lr_std : ${datamodule.lr_std}

mtf_parameters:
  _target_: tamrfsits.tasks.base.MTFParameters
  lr_mtf : ${datamodule.lr_mtf}
  hr_mtf : ${datamodule.hr_mtf}
  lr_resolution : ${datamodule.lr_resolution}
  hr_resolution : ${datamodule.hr_resolution}
  output_resolution : ${datamodule.output_resolution}
  learnable_mtfs: False

nb_latent_features : 64

parameters:
  _target_: tamrfsits.tasks.interpolation.training_module.TemporalInterpolationTrainingModuleParameters
  optimization: ${training_module.optimization_parameters}
  standardization: ${training_module.standardization_parameters}
  mtfs: ${training_module.mtf_parameters}
  hr2lr_loss_bands: ${datamodule.hr2lr_bands}
  lr2hr_loss_bands: ${datamodule.lr2hr_bands}
  loss_spatial_margin: 27
  cca_loss_weight: 1.0
  decorrelation_loss_weight: null
  min_clear_pixels_rate_for_data_loss: 0.5
  validation_random_seed: 42
  max_diff_for_data_loss : null
  use_triplet_loss: True
  resolutions_for_cca_loss:
    - _target_: tamrfsits.tasks.base.ResolutionForCCA
      ref_resolution : 10.
      pred_resolution : 20.
      per_date: True
      use_lpips: True
      high_pass_filtering_mode: "NO"
    - _target_: tamrfsits.tasks.base.ResolutionForCCA
      ref_resolution : 10.
      pred_resolution : 30.
      per_date: True
      use_lpips: True
      high_pass_filtering_mode: "NO"
    - _target_: tamrfsits.tasks.base.ResolutionForCCA
      ref_resolution : 10.
      pred_resolution : 90.
      per_date: True
      use_lpips: True
      include_hr_ndvi: True
      high_pass_filtering_mode: "NO"
      scale: 0.1

training_module:
  _target_: tamrfsits.tasks.interpolation.training_module.TemporalInterpolationTrainingModule
  config: ${training_module.parameters}
  encoder:
    _target_ : tamrfsits.components.transformer.TemporalEncoder
    hr_encoder: ${hr_encoder.model}
    lr_encoder: ${lr_encoder.model}
    temporal_positional_encoder: ${positional_encoding.model}
    token_size: ${training_module.nb_latent_features}
    nb_heads: 4
    nb_layers: 3
    dim_feedforward: 256
    sensor_token_size: 8
  decoder:
    _target_ : tamrfsits.components.transformer.TemporalDecoder
    decoder : ${decoder.model}
    temporal_positional_encoder: ${positional_encoding.model}
    token_size: ${training_module.nb_latent_features}
    nb_heads: 4
    sensor_token_size: 8
  cca_loss:
    # _target_: tamrfsits.core.cca.DatewiseLinearCCALoss
    # min_eigen_value: 0.1
    # spatial_margin : 5
    # loss:
    #   _target_: torch.nn.SmoothL1Loss
    #   beta: 0.1
    # high_pass_filtering: True
    # max_masked_rate_for_cca: 0.1
    _target_: tamrfsits.core.cca.DatewiseLinearRegressionLoss
    loss:
      _target_: torch.nn.SmoothL1Loss
      beta: 0.1
    mtf_for_high_pass_filtering: 0.3
    max_masked_rate: 0.25
